# Values needed for Triton Inference Server

# The path to the models directory
modelRepositoryPath: /opt/teknoir/models
# Models to be installed via a shared mounted host path (volume)
models: []
# Default annotations
annotations:
  teknoir.org/managed-by: devstudio
resources:
  limits:
    cpu: 2000m
    memory: 2048Mi
  requests:
    cpu: 400m
    memory: 256Mi